\section{Discussion}\label{sec:discussion}

\subsection{Context}

We only predict one possible outcome for a domain since we limit the predictions to endpaths within the same domain. There's often not that much choice within the same domain, so offering multiple predictions resembles guessing more rather than predicting. If the program were to be extended to find sequences of different domains however, then including an option to list the top 3 or 5 becomes a possibility.
\\[2ex]
Since we search for the end paths with the URL, some websites manage to go undetected. This is the case for websites that don't go deeper, but redirect to a sibling page instead. As mentioned in section~\ref{sec:truth}, the following sequence will not be detected:
\begin{verbatim}
www.kapaza.be,/nl/auto
www.kapaza.be,/nl/bmw
\end{verbatim}
It's also worth noting that when no predictions can be made, the current page will be the truth. It's not much of a prediction since you are already there, but it's more of an indication that there is currently nothing to predict. None of these issues subtract from the accuracy since the ground truth also does not take these into account. But we know that the \textit{real} accuracy is actually lower than the results we display. The accuracies we display represent more of an upper bound.
\\[2ex]
We offer a way to incrementally learn in our model. Every time we make a prediction, we reinforce our graph with the real url that the user wants to visit in accordance to the ground truth. The probabilities are then recomputed. While we cannot offer any useful prediction on unknown domains, we can learn from it so after a few times it may recognize a pattern. 
\\[2ex]
On the actual run of our program, we are no longer able to distinguish between ads and new domains because we will have no samples or clicks to compare the difference with. One fix to this would be to only consider clicked URL's, but from our observations sometimes a page is initially a load and only subsequent pages will result from clicks. This happens for example when using bookmarks. So to make sure we detect all input, we take the loads into consideration anyway.

\subsection{Results}\label{subsec:results}

There are two Excel files that contain the results for splitting the normal training/test dataset split and for k-fold cross validation respectively. From the results in the normal percentage based split, we notice that the higher the percentage of the training data is, the better the accuracy is. But that doesn't necessarily mean our model is performing any accurate predictions. When the model receives almost all information during the training phase, it will overfit on that data to predict even the irrelevant paths. The model uses too many complex parameters which introduces noise and lowers the overall accuracy. It can be difficult or even impossible to figure out what percentage split to choose to provide enough training data and prevent overfitting. That's why we use k-fold cross validation. For more information, we refer to section~\ref{sec:training}.
\\[2ex]
From the normal percentage split we sometimes observed quite a large variance in accuracy. When we compare this to the results from k-fold cross validation, we notice this is much less the case. The computed accuracies are much more consistent over the different users. The reasons for this have already been explained in section~\ref{sec:training}: the idea is that through partitioning and taking the average of recomputations, the variance will be much smaller. We also don't have to worry about overfitting as much.
\\[2ex]
Incremental learning doesn't seem to provide any real benefits on our current data, but is still important nonetheless. A model that does not apply incremental learning is not very dynamic and cannot cope with unknown domains in the future. We expect its real strength to come into play with much larger datasets.
\\[2ex]
Finally, it's quite obvious that taking all users into account does not perform as well as for individual users. This can be easily explained due to the different habits and preferences of users. Predictions based on all users can be useful if the majority tend to visit the same endpaths and even then it's only useful to that majority.